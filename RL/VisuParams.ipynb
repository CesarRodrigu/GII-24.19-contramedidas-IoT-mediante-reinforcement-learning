{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from custom_env.actions import Acciones\n",
    "from ipywidgets import interact,interactive_output\n",
    "from gymnasium import make\n",
    "from stable_baselines3 import PPO\n",
    "import ipywidgets\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.19045-SP0 10.0.19045\n",
      "- Python: 3.12.6\n",
      "- Stable-Baselines3: 2.4.1\n",
      "- PyTorch: 2.5.1+cpu\n",
      "- GPU Enabled: False\n",
      "- Numpy: 1.26.4\n",
      "- Cloudpickle: 3.1.0\n",
      "- Gymnasium: 1.0.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Windows-10-10.0.19045-SP0 10.0.19045\n",
      "- Python: 3.12.6\n",
      "- Stable-Baselines3: 2.4.1\n",
      "- PyTorch: 2.5.1+cpu\n",
      "- GPU Enabled: False\n",
      "- Numpy: 1.26.4\n",
      "- Cloudpickle: 3.1.0\n",
      "- Gymnasium: 1.0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 289980628190634006122751570777790489191\n",
    "name = \"./models/Example\"\n",
    "env_id = \"RouterEnv-v0\"\n",
    "\n",
    "env = make(env_id, seed=seed)\n",
    "seed: int = env.np_random_seed\n",
    "model = PPO.load(name, print_system_info=True)\n",
    "\n",
    "num_steps = 1\n",
    "obs, _ = env.reset(seed=seed)\n",
    "# Variables de información:\n",
    "\n",
    "stats = []\n",
    "rewards = []\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "ant = env._get_info()\n",
    "for episode in range(num_steps):\n",
    "\n",
    "    done = False\n",
    "    step_counter = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, terminated, info = env.step(action)\n",
    "\n",
    "        stats.append(info[\"Stats\"])\n",
    "        rewards.append(reward)\n",
    "\n",
    "        done: bool = done or terminated\n",
    "\n",
    "    env.reset(seed=seed)\n",
    "    step_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca0a1b0d8ed4c858c500b0fb78f7f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=8, description='descartados_range', max=20, min=1), IntSlider(value=3, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_reward(descartados_range=8, num=3)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir la función de recompensa\n",
    "\n",
    "\n",
    "def compute_reward(actual: float, descartados: int, action: Acciones) -> float:\n",
    "    reward: float = 0.0\n",
    "    c = 0.25\n",
    "    c1=0.5\n",
    "    if descartados > 0:\n",
    "        if action == Acciones.PERMITIR:\n",
    "            reward -= (descartados**2) * c1\n",
    "        else:\n",
    "            reward -= (descartados) * c\n",
    "    else:\n",
    "        reward += 1.0\n",
    "    return reward\n",
    "\n",
    "\n",
    "def create_plot(axes, fila, actual, valores, recompensas, accion: Acciones):\n",
    "    col: int = Acciones.action_to_int(accion)\n",
    "    axes[fila, col].plot(valores, recompensas, label='Reward')\n",
    "    axes[fila, col].set_xlabel('Descartados')\n",
    "    axes[fila, col].set_ylabel('Recompensa')\n",
    "    axes[fila, col].set_title(f'{accion.name} - Reward - {actual:.2f}')\n",
    "    axes[fila, col].legend()\n",
    "    axes[fila, col].grid(True)\n",
    "\n",
    "\n",
    "def plot_reward(descartados_range=8, num=3):\n",
    "    actual_values = np.linspace(0, 1, num)\n",
    "    descartados_values = np.arange(0, descartados_range + 1)\n",
    "    # assert actual_values.shape == descartados_values.shape\n",
    "\n",
    "    fig, axes = plt.subplots(num, 2, figsize=(10, num * 3))\n",
    "    axes = np.atleast_2d(axes)  # Asegurarse de que sea una matriz 2D\n",
    "\n",
    "    for i, actual in enumerate(actual_values):\n",
    "        recompensas_permitir: list[float] = [compute_reward(\n",
    "            actual, d, Acciones.PERMITIR) for d in descartados_values]\n",
    "        recompensas_denegar: list[float] = [compute_reward(\n",
    "            actual, d, Acciones.DENEGAR) for d in descartados_values]\n",
    "        create_plot(axes, i, actual, descartados_values,\n",
    "                    recompensas_permitir, Acciones.PERMITIR)\n",
    "        create_plot(axes, i, actual, descartados_values,\n",
    "                    recompensas_denegar, Acciones.DENEGAR)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Crear la interactividad\n",
    "interact(plot_reward, descartados_range=(1, 20, 1), num=(2, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6cc52ced34435081a692275ffb4f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='coef_actual', min=-100, step=5), IntSlider(value=96, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.generate_plot(coef_actual, coef_descartados, num_descartados=2)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import axes\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "def re_ocu(actual: float, coef=55) -> float:\n",
    "    reward = 0.0\n",
    "    reward += (1-actual)*coef\n",
    "    return reward\n",
    "\n",
    "\n",
    "def re_desca(descartados: float, coef=1.0) -> float:\n",
    "    reward = 0.0\n",
    "    if descartados > 0:\n",
    "        reward -= (descartados**2) * coef\n",
    "    else:\n",
    "        reward += 60.0\n",
    "    return reward\n",
    "\n",
    "\n",
    "def re_accion(action) -> float:\n",
    "    reward = 0.0\n",
    "    match action:\n",
    "        case Acciones.PERMITIR:\n",
    "            reward += 5.0\n",
    "        case Acciones.DENEGAR:\n",
    "            reward -= 2.0\n",
    "        case _:\n",
    "            reward += 0.0\n",
    "    return reward\n",
    "\n",
    "\n",
    "def plot_subplot(ax: axes._axes.Axes, datos_actual: list[float], recompensa_actual_in: list[float], datos_descartados: list[int], recompensa_descartados_in: list[float], accion: Acciones):\n",
    "\n",
    "    recompensa_actual = list(map(lambda x: x + re_accion(accion), recompensa_actual_in))\n",
    "    recompensa_descartados = list(map(lambda x: x + re_accion(accion), recompensa_descartados_in))\n",
    "\n",
    "\n",
    "    line1: list[Line2D] = ax.plot(datos_actual, recompensa_actual,\n",
    "                            label='Ocupación', color='blue')\n",
    "    \n",
    "    ax.set_xlabel('Ocupación')\n",
    "    ax.set_ylabel('Recompensa')\n",
    "    ax.spines['bottom'].set_color('blue')\n",
    "    ax.xaxis.label.set_color('blue')\n",
    "    ax.tick_params(axis='x', colors='blue')\n",
    "\n",
    "    ax2: axes.Axes = ax.twiny()\n",
    "    line2: Line2D = ax2.plot(\n",
    "        datos_descartados, recompensa_descartados, label='Descartados', color='red')\n",
    "    ax2.set_xlabel('Descartados')\n",
    "    ax2.spines['top'].set_color('red')\n",
    "    ax2.xaxis.label.set_color('red')\n",
    "    ax2.tick_params(axis='x', colors='red')\n",
    "\n",
    "    min_rew: float = min(recompensa_actual + recompensa_descartados)\n",
    "    max_rew: float = max(recompensa_actual + recompensa_descartados)\n",
    "    ax.set_ylim(min_rew, max_rew)\n",
    "    ax2.set_ylim(min_rew, max_rew)\n",
    "\n",
    "    lines: list[Line2D] = [*line1, *line2]\n",
    "    labels: list[object] = [line.get_label() for line in lines]\n",
    "    ax.legend(lines, labels)\n",
    "    ax.set_title(accion.name)\n",
    "\n",
    "\n",
    "def generate_subplots(axes, fila, datos_actual, datos_descartados, recompensa_actual, recompensa_descartados):\n",
    "    plot_subplot(axes[fila, 0], datos_actual, recompensa_actual,\n",
    "                 datos_descartados, recompensa_descartados, Acciones.PERMITIR)\n",
    "    plot_subplot(axes[fila, 1], datos_actual, recompensa_actual,\n",
    "                 datos_descartados, recompensa_descartados, Acciones.DENEGAR)\n",
    "\n",
    "\n",
    "def generate_plot(coef_actual, coef_descartados, num_descartados=2):\n",
    "    datos_actual = np.linspace(0, 1, num_descartados)\n",
    "    datos_descartados = np.arange(0, num_descartados + 1)\n",
    "\n",
    "    recompensa_actual = [re_ocu(a, coef=coef_actual) for a in datos_actual]\n",
    "    recompensa_descartados = [re_desca(d, coef=coef_descartados) for d in datos_descartados]\n",
    "    filas = 1\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, filas * 4))\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    generate_subplots(axes, 0, datos_actual, datos_descartados,\n",
    "                      recompensa_actual, recompensa_descartados)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(generate_plot, coef_actual=(-100, 100, 5),\n",
    "         coef_descartados=(1, 200, 5), num_descartados=(2, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValuesView(Dict('Descartados': Box(0, 9223372036854775807, (1,), int64), 'OcupacionCola': Box(0.0, 1.0, (1,), float32)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Descartados': array([0], dtype=int64),\n",
       " 'OcupacionCola': array([0.01386326], dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gymnasium.spaces import Box, Dict, Discrete\n",
    "\n",
    "observation_space = Dict({\n",
    "            \"OcupacionCola\": Box(low=0, high=1, dtype=np.float32),\n",
    "            \"Descartados\": Box(low=0, high=np.inf, dtype=np.int64),  \n",
    "        })\n",
    "print(observation_space.values())\n",
    "observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55029753e17490983cfd9240cd0fd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.25, description='c', max=1.0, step=0.05), FloatSlider(value=0.5, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_reward(c=0.25, c1=0.5, max_descartados=10)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_output(wait=True)\n",
    "\n",
    "\n",
    "def compute_reward(actual: float, descartados: int, action: Acciones, c: float, c1: float) -> float:\n",
    "\n",
    "    reward: float = 0.0\n",
    "    if descartados > 0:\n",
    "        if action == Acciones.PERMITIR:\n",
    "            reward -= (descartados ** 2) * c1\n",
    "        else:\n",
    "            reward -= (descartados) * c\n",
    "    else:\n",
    "        reward += 1.0\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "def plot_reward(c=0.25, c1=0.5, max_descartados=10):\n",
    "    descartados_range = np.arange(0, max_descartados + 1, 1)\n",
    "\n",
    "    rewards_permitir: list[float] = [compute_reward(\n",
    "        0.0, d, Acciones.PERMITIR, c, c1) for d in descartados_range]\n",
    "    rewards_bloquear: list[float] = [compute_reward(\n",
    "        0.0, d, Acciones.DENEGAR, c, c1) for d in descartados_range]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(descartados_range, rewards_permitir,\n",
    "             label=\"Acción: PERMITIR\", marker=\"o\", linestyle=\"--\")\n",
    "    plt.plot(descartados_range, rewards_bloquear,\n",
    "             label=\"Acción: DENEGAR\", marker=\"s\", linestyle=\"-\")\n",
    "\n",
    "    plt.axhline(0, color=\"black\", linewidth=1, linestyle=\"dotted\")\n",
    "\n",
    "    plt.xlabel(\"Descartados\")\n",
    "    plt.ylabel(\"Recompensa\")\n",
    "    plt.title(\"Impacto de c y c1 en la recompensa\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Crear widgets interactivos\n",
    "interact(plot_reward,\n",
    "         c=(0, 1, 0.05),\n",
    "         c1=(0, 1, 0.05),\n",
    "         max_descartados=(5, 50, 1),\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f09693b8e4244f78b2825e4da3ac73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.25, description='c', max=4.0, step=0.05), FloatSlider(value=0.5, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_reward(c=0.25, c1=0.5, max_descartados=10)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Función para calcular la recompensa\n",
    "def compute_reward(actual: float, descartados: int, action: Acciones, c: float, c1: float) -> float:\n",
    "    reward: float = 0.0\n",
    "    if descartados > 0:\n",
    "        if action == Acciones.PERMITIR:\n",
    "            reward -= (descartados ** 2) * c1\n",
    "        else:\n",
    "            reward -= (descartados) * c\n",
    "    else:\n",
    "        reward += 1.0\n",
    "\n",
    "    return reward\n",
    "\n",
    "# Función para graficar la recompensa en función de c y c1\n",
    "def plot_reward(c=0.25, c1=0.5, max_descartados=10):\n",
    "    descartados_range = np.arange(0, max_descartados + 1, 1)\n",
    "\n",
    "    # Calcular recompensas para cada acción\n",
    "    rewards_permitir = [compute_reward(0.0, d, Acciones.PERMITIR, c, c1) for d in descartados_range]\n",
    "    rewards_bloquear = [compute_reward(0.0, d, Acciones.DENEGAR, c, c1) for d in descartados_range]\n",
    "\n",
    "    # Graficar las recompensas\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(descartados_range, rewards_permitir, label=\"Acción: PERMITIR\", marker=\"o\", linestyle=\"--\")\n",
    "    plt.plot(descartados_range, rewards_bloquear, label=\"Acción: DENEGAR\", marker=\"s\", linestyle=\"-\")\n",
    "    plt.axhline(0, color=\"black\", linewidth=1, linestyle=\"dotted\")\n",
    "\n",
    "    # Etiquetas y título\n",
    "    plt.xlabel(\"Descartados\")\n",
    "    plt.ylabel(\"Recompensa\")\n",
    "    plt.title(\"Impacto de c y c1 en la recompensa\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Crear widgets interactivos\n",
    "interact(plot_reward,\n",
    "         c=(0, 4, 0.05),\n",
    "         c1=(0, 4, 0.05),\n",
    "         max_descartados=(5, 50, 1),\n",
    "         )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
